{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu5Xpq5ECSgy"
      },
      "source": [
        "# 1. Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Nl8ioa0vIr65"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import threading\n",
        "import random\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Activation\n",
        "from tensorflow.keras.layers import Conv2D, Reshape, Conv3D, AveragePooling2D, Lambda, UpSampling2D, UpSampling3D, GlobalAveragePooling3D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate, add, multiply\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import array_ops\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx4kFUMDg3zw",
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "GPU setting ( Our setting: rtx 3090,\n",
        "                            gpu number = 0 )\n",
        "'''\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "! export TF_GPU_ALLOCATOR=cuda_malloc_async"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-aDkkE-BOlT"
      },
      "source": [
        "# 2. Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfXTia9rBkdF"
      },
      "source": [
        "## 2.1. generate_traindata_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBhukI6W3x-z",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def generate_traindata_for_train(traindata_all, traindata_label, input_size,\n",
        "                                 label_size, batch_size,\n",
        "                                 Setting02_AngualrViews, boolmask_img4,\n",
        "                                 boolmask_img6, boolmask_img15):\n",
        "    \"\"\"\n",
        "     input: traindata_all   (16x128x128x9x9x3) uint8\n",
        "            traindata_label (16x128x128x9x9)   float32\n",
        "            input_size 23~   int\n",
        "            label_size 1~    int\n",
        "            batch_size 16    int\n",
        "            Setting02_AngualrViews [0,1,2,3,4,5,6,7,8] for 9x9\n",
        "            boolmask_img4 (128x128)  bool // reflection mask for images[4]\n",
        "            boolmask_img6 (128x128)  bool // reflection mask for images[6]\n",
        "            boolmask_img15 (128x128) bool // reflection mask for images[15]\n",
        "\n",
        "\n",
        "     Generate traindata using LF image and disparity map\n",
        "     by randomly chosen variables.\n",
        "     1.  gray image: random R,G,B --> R*img_R + G*img_G + B*imgB\n",
        "     2.  patch-wise learning: random x,y  --> LFimage[x:x+size1,y:y+size2]\n",
        "     3.  scale augmentation: scale 1,2,3  --> ex> LFimage[x:x+2*size1:2,y:y+2*size2:2]\n",
        "\n",
        "     output: traindata_batch   (batch_size x input_size x input_size x len(Setting02_AngualrViews)) float32\n",
        "             traindata_batch_label (batch_size x label_size x label_size )                   float32\n",
        "    \"\"\"\n",
        "    \"\"\" initialize image_stack & label \"\"\"\n",
        "    traindata_batch = np.zeros(\n",
        "        (batch_size, input_size, input_size, len(Setting02_AngualrViews),\n",
        "         len(Setting02_AngualrViews)),\n",
        "        dtype=np.float32)\n",
        "\n",
        "    traindata_batch_label = np.zeros((batch_size, label_size, label_size))\n",
        "    \"\"\" inital variable \"\"\"\n",
        "    crop_half1 = int(0.5 * (input_size - label_size))\n",
        "    \"\"\" Generate image stacks\"\"\"\n",
        "    for ii in range(0, batch_size):\n",
        "        sum_diff = 0\n",
        "        valid = 0\n",
        "\n",
        "        while (sum_diff < 0.01 * input_size * input_size or valid < 1):\n",
        "            \"\"\"//Variable for gray conversion//\"\"\"\n",
        "            rand_3color = 0.05 + np.random.rand(3)\n",
        "            rand_3color = rand_3color / np.sum(rand_3color)\n",
        "            R = rand_3color[0]\n",
        "            G = rand_3color[1]\n",
        "            B = rand_3color[2]\n",
        "            \"\"\"\n",
        "                We use totally 16 LF images,(0 to 15)\n",
        "                Since some images(4,6,15) have a reflection region,\n",
        "                We decrease frequency of occurrence for them.\n",
        "            \"\"\"\n",
        "            # Use for fold 1\n",
        "            aa_arr = np.array([\n",
        "                0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 5, 7,\n",
        "                8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12,\n",
        "                13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n",
        "            ])\n",
        "            # Use for fold 2\n",
        "            # aa_arr = np.array([\n",
        "            #     0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1, 2, 3, 5, 7,\n",
        "            #     8, 9, 10, 11, 12, 13, 14, 15, 0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12,\n",
        "            #     13, 14, 15, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n",
        "            # ])\n",
        "\n",
        "            # Use for fold 3\n",
        "            # aa_arr = np.array([\n",
        "            #     0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7,\n",
        "            #     8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
        "            #     13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n",
        "            # ])\n",
        "            image_id = np.random.choice(aa_arr)\n",
        "\n",
        "            if (len(Setting02_AngualrViews) == 9):\n",
        "                ix_rd = 0\n",
        "                iy_rd = 0\n",
        "\n",
        "            kk = np.random.randint(17)\n",
        "            if (kk < 8):\n",
        "                scale = 1\n",
        "            elif (kk < 14):\n",
        "                scale = 2\n",
        "            elif (kk < 17):\n",
        "                scale = 3\n",
        "\n",
        "            idx_start = np.random.randint(0, 128 - scale * input_size)\n",
        "            idy_start = np.random.randint(0, 128 - scale * input_size)\n",
        "            valid = 1\n",
        "            \"\"\"\n",
        "                boolmask: reflection masks for images(4,6,15)\n",
        "            \"\"\"\n",
        "            # Comment out for fold 3\n",
        "            if (image_id == 4 or 6 or 15):\n",
        "                if (image_id == 4):\n",
        "                    a_tmp = boolmask_img4\n",
        "                    if (np.sum(a_tmp[\n",
        "                            idx_start + scale * crop_half1:idx_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale,\n",
        "                            idy_start + scale * crop_half1:idy_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale]) > 0\n",
        "                            or np.sum(a_tmp[idx_start:idx_start +\n",
        "                                            scale * input_size:scale,\n",
        "                                            idy_start:idy_start +\n",
        "                                            scale * input_size:scale]) > 0):\n",
        "                        valid = 0\n",
        "                if (image_id == 6):\n",
        "                    a_tmp = boolmask_img6\n",
        "                    if (np.sum(a_tmp[\n",
        "                            idx_start + scale * crop_half1:idx_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale,\n",
        "                            idy_start + scale * crop_half1:idy_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale]) > 0\n",
        "                            or np.sum(a_tmp[idx_start:idx_start +\n",
        "                                            scale * input_size:scale,\n",
        "                                            idy_start:idy_start +\n",
        "                                            scale * input_size:scale]) > 0):\n",
        "                        valid = 0\n",
        "                # Comment out for fold 2\n",
        "                if (image_id == 15):\n",
        "                    a_tmp = boolmask_img15\n",
        "                    if (np.sum(a_tmp[\n",
        "                            idx_start + scale * crop_half1:idx_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale,\n",
        "                            idy_start + scale * crop_half1:idy_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale]) > 0\n",
        "                            or np.sum(a_tmp[idx_start:idx_start +\n",
        "                                            scale * input_size:scale,\n",
        "                                            idy_start:idy_start +\n",
        "                                            scale * input_size:scale]) > 0):\n",
        "                        valid = 0\n",
        "\n",
        "            if (valid > 0):\n",
        "\n",
        "                image_center = (1 / 255) * np.squeeze(\n",
        "                    R * traindata_all[image_id, idx_start:idx_start + scale *\n",
        "                                      input_size:scale, idy_start:idy_start +\n",
        "                                      scale * input_size:scale, 4 + ix_rd,\n",
        "                                      4 + iy_rd, 0].astype('float32') +\n",
        "                    G * traindata_all[image_id, idx_start:idx_start + scale *\n",
        "                                      input_size:scale, idy_start:idy_start +\n",
        "                                      scale * input_size:scale, 4 + ix_rd,\n",
        "                                      4 + iy_rd, 1].astype('float32') +\n",
        "                    B * traindata_all[image_id, idx_start:idx_start + scale *\n",
        "                                      input_size:scale, idy_start:idy_start +\n",
        "                                      scale * input_size:scale, 4 + ix_rd,\n",
        "                                      4 + iy_rd, 2].astype('float32'))\n",
        "                sum_diff = np.sum(\n",
        "                    np.abs(image_center -\n",
        "                           np.squeeze(image_center[int(0.5 * input_size),\n",
        "                                                   int(0.5 * input_size)])))\n",
        "\n",
        "                traindata_batch[ii, :, :, :, :] = np.squeeze(\n",
        "                    R * traindata_all[\n",
        "                        image_id:image_id + 1, idx_start:idx_start +\n",
        "                        scale * input_size:scale, idy_start:idy_start +\n",
        "                        scale * input_size:scale, :, :, 0].astype('float32') +\n",
        "                    G * traindata_all[\n",
        "                        image_id:image_id + 1, idx_start:idx_start +\n",
        "                        scale * input_size:scale, idy_start:idy_start +\n",
        "                        scale * input_size:scale, :, :, 1].astype('float32') +\n",
        "                    B * traindata_all[\n",
        "                        image_id:image_id + 1, idx_start:idx_start +\n",
        "                        scale * input_size:scale, idy_start:idy_start +\n",
        "                        scale * input_size:scale, :, :, 2].astype('float32'))\n",
        "                '''\n",
        "                 traindata_batch_label  <-- scale_factor*traindata_label[random_index, scaled_label_size, scaled_label_size]\n",
        "                '''\n",
        "                if (len(traindata_label.shape) == 5):\n",
        "                    traindata_batch_label[\n",
        "                        ii, :, :] = (1.0 / scale) * traindata_label[\n",
        "                            image_id, idx_start +\n",
        "                            scale * crop_half1:idx_start + scale * crop_half1 +\n",
        "                            scale * label_size:scale, idy_start +\n",
        "                            scale * crop_half1:idy_start + scale * crop_half1 +\n",
        "                            scale * label_size:scale, 4 + ix_rd, 4 + iy_rd]\n",
        "                else:\n",
        "                    traindata_batch_label[\n",
        "                        ii, :, :] = (1.0 / scale) * traindata_label[\n",
        "                            image_id,\n",
        "                            idx_start + scale * crop_half1:idx_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale,\n",
        "                            idy_start + scale * crop_half1:idy_start +\n",
        "                            scale * crop_half1 + scale * label_size:scale]\n",
        "\n",
        "    traindata_batch = np.float32((1 / 255) * traindata_batch)\n",
        "\n",
        "    return traindata_batch, traindata_batch_label\n",
        "\n",
        "\n",
        "\"\"\" (v, u) \"\"\"\n",
        "\"\"\" (0, 0) (0, 1) (0, 2) (0, 3) (0, 4) (0, 5) (0, 6) (0, 7) (0, 8)\"\"\"\n",
        "\"\"\" (1, 0) (1, 1) (1, 2) (1, 3) (1, 4) (1, 5) (1, 6) (1, 7) (1, 8)\"\"\"\n",
        "\"\"\" (2, 0) (2, 1) (2, 2) (2, 3) (2, 4) (2, 5) (2, 6) (2, 7) (2, 8)\"\"\"\n",
        "\"\"\" (3, 0) (3, 1) (3, 2) (3, 3) (3, 4) (3, 5) (3, 6) (3, 7) (3, 8)\"\"\"\n",
        "\"\"\" (4, 0) (4, 1) (4, 2) (4, 3) (4, 4) (4, 5) (4, 6) (4, 7) (4, 8)\"\"\"\n",
        "\"\"\" (5, 0) (5, 1) (5, 2) (5, 3) (5, 4) (5, 5) (5, 6) (5, 7) (5, 8)\"\"\"\n",
        "\"\"\" (6, 0) (6, 1) (6, 2) (6, 3) (6, 4) (6, 5) (6, 6) (6, 7) (6, 8)\"\"\"\n",
        "\"\"\" (7, 0) (7, 1) (7, 2) (7, 3) (7, 4) (7, 5) (7, 6) (7, 7) (7, 8)\"\"\"\n",
        "\"\"\" (8, 0) (8, 1) (8, 2) (8, 3) (8, 4) (8, 5) (8, 6) (8, 7) (8, 8)\"\"\"\n",
        "\n",
        "\n",
        "def data_augmentation_for_train(traindata_batch, traindata_label_batchNxN,\n",
        "                                batch_size):\n",
        "    \"\"\"\n",
        "        For Data augmentation\n",
        "        (rotation, transpose and gamma)\n",
        "    \"\"\"\n",
        "\n",
        "    for batch_i in range(batch_size):\n",
        "        gray_rand = 0.4 * np.random.rand() + 0.8\n",
        "\n",
        "        traindata_batch[batch_i, :, :, :, :] = pow(\n",
        "            traindata_batch[batch_i, :, :, :, :], gray_rand)\n",
        "        \"\"\" transpose \"\"\"\n",
        "        transp_rand = np.random.randint(0, 2)\n",
        "        if transp_rand == 1:\n",
        "            traindata_batch_tmp6 = np.copy(\n",
        "                np.rot90(\n",
        "                    np.transpose(\n",
        "                        np.squeeze(traindata_batch[batch_i, :, :, :, :]),\n",
        "                        (1, 0, 2, 3))))\n",
        "            traindata_batch[\n",
        "                batch_i, :, :, :, :] = traindata_batch_tmp6[:, :, ::-1]\n",
        "            traindata_label_batchNxN_tmp6 = np.copy(\n",
        "                np.rot90(\n",
        "                    np.transpose(traindata_label_batchNxN[batch_i, :, :],\n",
        "                                 (1, 0))))\n",
        "            traindata_label_batchNxN[\n",
        "                batch_i, :, :] = traindata_label_batchNxN_tmp6\n",
        "        \"\"\" rotation \"\"\"\n",
        "        rotation_rand = np.random.randint(0, 4)\n",
        "        \"\"\" 90 \"\"\"\n",
        "        if rotation_rand == 1:\n",
        "            traindata_batch_tmp6 = np.copy(\n",
        "                np.rot90(np.squeeze(traindata_batch[batch_i, :, :, :, :])))\n",
        "            traindata_batch[batch_i, :, :, :, :] = np.copy(\n",
        "                np.rot90(traindata_batch_tmp6, 1, (2, 3)))\n",
        "            traindata_label_batchNxN_tmp6 = np.copy(\n",
        "                np.rot90(traindata_label_batchNxN[batch_i, :, :]))\n",
        "            traindata_label_batchNxN[\n",
        "                batch_i, :, :] = traindata_label_batchNxN_tmp6\n",
        "        \"\"\" 180 \"\"\"\n",
        "        if rotation_rand == 2:\n",
        "            traindata_batch_tmp6 = np.copy(\n",
        "                np.rot90(np.squeeze(traindata_batch[batch_i, :, :, :, :]), 2))\n",
        "            traindata_batch[batch_i, :, :, :, :] = np.copy(\n",
        "                np.rot90(traindata_batch_tmp6, 2, (2, 3)))\n",
        "            traindata_label_batchNxN_tmp6 = np.copy(\n",
        "                np.rot90(traindata_label_batchNxN[batch_i, :, :], 2))\n",
        "            traindata_label_batchNxN[\n",
        "                batch_i, :, :] = traindata_label_batchNxN_tmp6\n",
        "        \"\"\" 270 \"\"\"\n",
        "        if rotation_rand == 3:\n",
        "            traindata_batch_tmp6 = np.copy(\n",
        "                np.rot90(np.squeeze(traindata_batch[batch_i, :, :, :, :]), 3))\n",
        "            traindata_batch[batch_i, :, :, :, :] = np.copy(\n",
        "                np.rot90(traindata_batch_tmp6, 3, (2, 3)))\n",
        "            traindata_label_batchNxN_tmp6 = np.copy(\n",
        "                np.rot90(traindata_label_batchNxN[batch_i, :, :], 3))\n",
        "            traindata_label_batchNxN[\n",
        "                batch_i, :, :] = traindata_label_batchNxN_tmp6\n",
        "        \"\"\" gaussian noise \"\"\"\n",
        "        noise_rand = np.random.randint(0, 12)\n",
        "        if noise_rand == 0:\n",
        "            gauss = np.random.normal(\n",
        "                0.0,\n",
        "                np.random.uniform() * np.sqrt(0.2),\n",
        "                (traindata_batch.shape[1], traindata_batch.shape[2],\n",
        "                 traindata_batch.shape[3], traindata_batch.shape[4]))\n",
        "            traindata_batch[batch_i, :, :, :, :] = np.clip(\n",
        "                traindata_batch[batch_i, :, :, :, :] + gauss, 0.0, 1.0)\n",
        "\n",
        "    return traindata_batch, traindata_label_batchNxN\n",
        "\n",
        "\n",
        "def generate_traindata128(traindata_all, traindata_label,\n",
        "                          Setting02_AngualrViews):\n",
        "    \"\"\"\n",
        "    Generate validation or test set( = full size(128x128) LF images)\n",
        "\n",
        "     input: traindata_all   (16x128x128x9x9x3) uint8\n",
        "            traindata_label (16x128x128x9x9)   float32\n",
        "            Setting02_AngualrViews [0,1,2,3,4,5,6,7,8] for 9x9\n",
        "\n",
        "\n",
        "     output: traindata_batch_list   (batch_size x 128 x 128 x len(Setting02_AngualrViews)) float32\n",
        "             traindata_label_batchNxN (batch_size x 128 x 128 )               float32\n",
        "    \"\"\"\n",
        "\n",
        "    input_size = 128\n",
        "    label_size = 128\n",
        "    traindata_batch = np.zeros(\n",
        "        (len(traindata_all), input_size, input_size,\n",
        "         len(Setting02_AngualrViews), len(Setting02_AngualrViews)),\n",
        "        dtype=np.float32)\n",
        "\n",
        "    traindata_label_batchNxN = np.zeros(\n",
        "        (len(traindata_all), label_size, label_size))\n",
        "    \"\"\" inital setting \"\"\"\n",
        "    ### sz = (16, 27, 9, 128, 128)\n",
        "\n",
        "    crop_half1 = int(0.5 * (input_size - label_size))\n",
        "\n",
        "    for ii in range(0, len(traindata_all)):\n",
        "\n",
        "        R = 0.299  ### 0,1,2,3 = R, G, B, Gray // 0.299 0.587 0.114\n",
        "        G = 0.587\n",
        "        B = 0.114\n",
        "\n",
        "        image_id = ii\n",
        "\n",
        "        ix_rd = 0\n",
        "        iy_rd = 0\n",
        "        idx_start = 0\n",
        "        idy_start = 0\n",
        "\n",
        "        traindata_batch[ii, :, :, :, :] = np.squeeze(\n",
        "            R * traindata_all[image_id:image_id + 1, idx_start:idx_start +\n",
        "                              input_size, idy_start:idy_start +\n",
        "                              input_size, :, :, 0].astype('float32') +\n",
        "            G * traindata_all[image_id:image_id + 1, idx_start:idx_start +\n",
        "                              input_size, idy_start:idy_start +\n",
        "                              input_size, :, :, 1].astype('float32') +\n",
        "            B * traindata_all[image_id:image_id + 1, idx_start:idx_start +\n",
        "                              input_size, idy_start:idy_start +\n",
        "                              input_size, :, :, 2].astype('float32'))\n",
        "\n",
        "        if (len(traindata_all) >= 12 and traindata_label.shape[-1] == 9):\n",
        "            traindata_label_batchNxN[ii, :, :] = traindata_label[\n",
        "                image_id,\n",
        "                idx_start + crop_half1:idx_start + crop_half1 + label_size,\n",
        "                idy_start + crop_half1:idy_start + crop_half1 + label_size,\n",
        "                4 + ix_rd, 4 + iy_rd]\n",
        "        elif (len(traindata_label.shape) == 5):\n",
        "            traindata_label_batchNxN[ii, :, :] = traindata_label[\n",
        "                image_id,\n",
        "                idx_start + crop_half1:idx_start + crop_half1 + label_size,\n",
        "                idy_start + crop_half1:idy_start + crop_half1 + label_size, 0,\n",
        "                0]\n",
        "        else:\n",
        "            traindata_label_batchNxN[ii, :, :] = traindata_label[\n",
        "                image_id,\n",
        "                idx_start + crop_half1:idx_start + crop_half1 + label_size,\n",
        "                idy_start + crop_half1:idy_start + crop_half1 + label_size]\n",
        "\n",
        "    traindata_batch = np.float32((1 / 255) * traindata_batch)\n",
        "\n",
        "    traindata_batch = np.minimum(np.maximum(traindata_batch, 0), 1)\n",
        "\n",
        "    traindata_batch_list = []\n",
        "    for i in range(traindata_batch.shape[3]):\n",
        "        for j in range(traindata_batch.shape[4]):\n",
        "            traindata_batch_list.append(\n",
        "                np.expand_dims(traindata_batch[:, :, :, i, j], axis=-1))\n",
        "\n",
        "    return traindata_batch_list, traindata_label_batchNxN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy1Rpt34J7Fd"
      },
      "source": [
        "## 2.2. model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qicEd_hAKJTZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def convbn(input, out_planes, kernel_size, stride, dilation):\n",
        "\n",
        "    seq = Conv2D(out_planes,\n",
        "                 kernel_size,\n",
        "                 stride,\n",
        "                 'same',\n",
        "                 dilation_rate=dilation,\n",
        "                 use_bias=False)(input)\n",
        "    seq = BatchNormalization()(seq)\n",
        "\n",
        "    return seq\n",
        "\n",
        "\n",
        "def convbn_3d(input, out_planes, kernel_size, stride):\n",
        "    seq = Conv3D(out_planes, kernel_size, stride, 'same',\n",
        "                 use_bias=False)(input)\n",
        "    seq = BatchNormalization()(seq)\n",
        "\n",
        "    return seq\n",
        "\n",
        "\n",
        "def BasicBlock(input, planes, stride, downsample, dilation):\n",
        "    conv1 = convbn(input, planes, 3, stride, dilation)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv2 = convbn(conv1, planes, 3, 1, dilation)\n",
        "    if downsample is not None:\n",
        "        input = downsample\n",
        "\n",
        "    conv2 = add([conv2, input])\n",
        "    return conv2\n",
        "\n",
        "\n",
        "def _make_layer(input, planes, blocks, stride, dilation):\n",
        "    inplanes = 4\n",
        "    downsample = None\n",
        "    if stride != 1 or inplanes != planes:\n",
        "        downsample = Conv2D(planes, 1, stride, 'same', use_bias=False)(input)\n",
        "        downsample = BatchNormalization()(downsample)\n",
        "\n",
        "    layers = BasicBlock(input, planes, stride, downsample, dilation)\n",
        "    for i in range(1, blocks):\n",
        "        layers = BasicBlock(layers, planes, 1, None, dilation)\n",
        "\n",
        "    return layers\n",
        "\n",
        "\n",
        "def UpSampling2DBilinear(size):\n",
        "    return Lambda(lambda x: tf.compat.v1.image.resize_bilinear(\n",
        "        x, size, align_corners=True))\n",
        "\n",
        "\n",
        "def UpSampling3DBilinear(size):\n",
        "\n",
        "    def UpSampling3DBilinear_(x, size):\n",
        "        shape = K.shape(x)\n",
        "        x = K.reshape(x, (shape[0] * shape[1], shape[2], shape[3], shape[4]))\n",
        "        x = tf.image.resize_bilinear(x, size, align_corners=True)\n",
        "        x = K.reshape(x, (shape[0], shape[1], size[0], size[1], shape[4]))\n",
        "        return x\n",
        "\n",
        "    return Lambda(lambda x: UpSampling3DBilinear_(x, size))\n",
        "\n",
        "\n",
        "def feature_extraction(sz_input, sz_input2):\n",
        "    i = Input(shape=(sz_input, sz_input2, 1))\n",
        "    firstconv = convbn(i, 4, 3, 1, 1)\n",
        "    firstconv = Activation('relu')(firstconv)\n",
        "    firstconv = convbn(firstconv, 4, 3, 1, 1)\n",
        "    firstconv = Activation('relu')(firstconv)\n",
        "\n",
        "    layer1 = _make_layer(firstconv, 4, 2, 1, 1)\n",
        "    layer2 = _make_layer(layer1, 8, 8, 1, 1)\n",
        "    layer3 = _make_layer(layer2, 16, 2, 1, 1)\n",
        "    layer4 = _make_layer(layer3, 16, 2, 1, 2)\n",
        "\n",
        "    layer4_size = (layer4.get_shape().as_list()[1],\n",
        "                   layer4.get_shape().as_list()[2])\n",
        "\n",
        "    branch1 = AveragePooling2D((2, 2), (2, 2), 'same')(layer4)\n",
        "    branch1 = convbn(branch1, 4, 1, 1, 1)\n",
        "    branch1 = Activation('relu')(branch1)\n",
        "    branch1 = UpSampling2DBilinear(layer4_size)(branch1)\n",
        "\n",
        "    branch2 = AveragePooling2D((4, 4), (4, 4), 'same')(layer4)\n",
        "    branch2 = convbn(branch2, 4, 1, 1, 1)\n",
        "    branch2 = Activation('relu')(branch2)\n",
        "    branch2 = UpSampling2DBilinear(layer4_size)(branch2)\n",
        "\n",
        "    branch3 = AveragePooling2D((8, 8), (8, 8), 'same')(layer4)\n",
        "    branch3 = convbn(branch3, 4, 1, 1, 1)\n",
        "    branch3 = Activation('relu')(branch3)\n",
        "    branch3 = UpSampling2DBilinear(layer4_size)(branch3)\n",
        "\n",
        "    branch4 = AveragePooling2D((16, 16), (16, 16), 'same')(layer4)\n",
        "    branch4 = convbn(branch4, 4, 1, 1, 1)\n",
        "    branch4 = Activation('relu')(branch4)\n",
        "    branch4 = UpSampling2DBilinear(layer4_size)(branch4)\n",
        "\n",
        "    output_feature = concatenate(\n",
        "        [layer2, layer4, branch4, branch3, branch2, branch1])\n",
        "    lastconv = convbn(output_feature, 16, 3, 1, 1)\n",
        "    lastconv = Activation('relu')(lastconv)\n",
        "    lastconv = Conv2D(4, 1, (1, 1), 'same', use_bias=False)(lastconv)\n",
        "\n",
        "    model = Model(inputs=[i], outputs=[lastconv])\n",
        "\n",
        "    return model\n",
        "\n",
        "def _getCostVolume_(inputs):\n",
        "    shape = K.shape(inputs[0])\n",
        "    disparity_values = np.linspace(-4, 4, 9)\n",
        "    disparity_costs = []\n",
        "    for d in disparity_values:\n",
        "        if d == 0:\n",
        "            tmp_list = []\n",
        "            for i in range(len(inputs)):\n",
        "                tmp_list.append(inputs[i])\n",
        "        else:\n",
        "            tmp_list = []\n",
        "            for i in range(len(inputs)):\n",
        "                (v, u) = divmod(i, 9)\n",
        "                tensor = tfa.image.translate(inputs[i],\n",
        "                                             [d * (u - 4), d * (v - 4)],\n",
        "                                             'BILINEAR')\n",
        "                tmp_list.append(tensor)\n",
        "\n",
        "        cost = K.concatenate(tmp_list, axis=3)\n",
        "        disparity_costs.append(cost)\n",
        "    cost_volume = K.stack(disparity_costs, axis=1)\n",
        "    cost_volume = K.reshape(cost_volume,\n",
        "                            (shape[0], len(disparity_values), shape[1], shape[2], 4 * 81))\n",
        "    return cost_volume\n",
        "\n",
        "def channel_attention(cost_volume):\n",
        "    x = GlobalAveragePooling3D()(cost_volume)\n",
        "    x = Lambda(\n",
        "        lambda y: K.expand_dims(K.expand_dims(K.expand_dims(y, 1), 1), 1))(x)\n",
        "    x = Conv3D(170, 1, 1, 'same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv3D(15, 1, 1, 'same')(x)  # [B, 1, 1, 1, 15]\n",
        "    x = Activation('sigmoid')(x)\n",
        "\n",
        "    # 15 -> 25\n",
        "    # 0  1  2  3  4\n",
        "    #    5  6  7  8\n",
        "    #       9 10 11\n",
        "    #         12 13\n",
        "    #            14\n",
        "    #\n",
        "    # 0  1  2  3  4\n",
        "    # 1  5  6  7  8\n",
        "    # 2  6  9 10 11\n",
        "    # 3  7 10 12 13\n",
        "    # 4  8 11 13 14\n",
        "\n",
        "    x = Lambda(lambda y: K.concatenate([\n",
        "        y[:, :, :, :, 0:5], y[:, :, :, :, 1:2], y[:, :, :, :, 5:9],\n",
        "        y[:, :, :, :, 2:3], y[:, :, :, :, 6:7], y[:, :, :, :, 9:12],\n",
        "        y[:, :, :, :, 3:4], y[:, :, :, :, 7:8], y[:, :, :, :, 10:11],\n",
        "        y[:, :, :, :, 12:14], y[:, :, :, :, 4:5], y[:, :, :, :, 8:9],\n",
        "        y[:, :, :, :, 11:12], y[:, :, :, :, 13:15]\n",
        "    ],\n",
        "                                       axis=-1))(x)\n",
        "\n",
        "    x = Lambda(lambda y: K.reshape(y, (K.shape(y)[0], 5, 5)))(x)\n",
        "    x = Lambda(lambda y: tf.pad(y, [[0, 0], [0, 4], [0, 4]], 'REFLECT'))(x)\n",
        "    attention = Lambda(lambda y: K.reshape(y, (K.shape(y)[0], 1, 1, 1, 81)))(x)\n",
        "    x = Lambda(lambda y: K.repeat_elements(y, 4, -1))(attention)\n",
        "    return multiply([x, cost_volume]), attention\n",
        "\n",
        "\n",
        "def channel_attention_free(cost_volume):\n",
        "    x = GlobalAveragePooling3D()(cost_volume)\n",
        "    x = Lambda(\n",
        "        lambda y: K.expand_dims(K.expand_dims(K.expand_dims(y, 1), 1), 1))(x)\n",
        "    x = Conv3D(170, 1, 1, 'same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv3D(81, 1, 1, 'same')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    attention = Lambda(lambda y: K.reshape(y, (K.shape(y)[0], 1, 1, 1, 81)))(x)\n",
        "    x = Lambda(lambda y: K.repeat_elements(y, 4, -1))(attention)\n",
        "    return multiply([x, cost_volume]), attention\n",
        "\n",
        "\n",
        "def channel_attention_mirror(cost_volume):\n",
        "    x = GlobalAveragePooling3D()(cost_volume)\n",
        "    x = Lambda(\n",
        "        lambda y: K.expand_dims(K.expand_dims(K.expand_dims(y, 1), 1), 1))(x)\n",
        "    x = Conv3D(170, 1, 1, 'same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv3D(25, 1, 1, 'same')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    x = Lambda(lambda y: K.reshape(y, (K.shape(y)[0], 5, 5)))(x)\n",
        "    x = Lambda(lambda y: tf.pad(y, [[0, 0], [0, 4], [0, 4]], 'REFLECT'))(x)\n",
        "    attention = Lambda(lambda y: K.reshape(y, (K.shape(y)[0], 1, 1, 1, 81)))(x)\n",
        "    x = Lambda(lambda y: K.repeat_elements(y, 4, -1))(attention)\n",
        "    return multiply([x, cost_volume]), attention\n",
        "\n",
        "\n",
        "def basic(cost_volume):\n",
        "\n",
        "    feature = 2 * 75\n",
        "    dres0 = convbn_3d(cost_volume, feature, 3, 1)\n",
        "    dres0 = Activation('relu')(dres0)\n",
        "    dres0 = convbn_3d(dres0, feature, 3, 1)\n",
        "    cost0 = Activation('relu')(dres0)\n",
        "\n",
        "    dres1 = convbn_3d(cost0, feature, 3, 1)\n",
        "    dres1 = Activation('relu')(dres1)\n",
        "    dres1 = convbn_3d(dres1, feature, 3, 1)\n",
        "    cost0 = add([dres1, cost0])\n",
        "\n",
        "    dres4 = convbn_3d(cost0, feature, 3, 1)\n",
        "    dres4 = Activation('relu')(dres4)\n",
        "    dres4 = convbn_3d(dres4, feature, 3, 1)\n",
        "    cost0 = add([dres4, cost0])\n",
        "\n",
        "    classify = convbn_3d(cost0, feature, 3, 1)\n",
        "    classify = Activation('relu')(classify)\n",
        "    cost = Conv3D(1, 3, 1, 'same', use_bias=False)(classify)\n",
        "\n",
        "    return cost\n",
        "\n",
        "class BSplineLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"BSpline\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        # Ensure float32 for consistency with typical NN layers\n",
        "        self.d = tf.constant([-4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=tf.float32)\n",
        "        self.C_dim = 9\n",
        "        # Epsilon as constant tensor for graph mode compatibility\n",
        "        self.eps = tf.constant(1e-8, dtype=tf.float32)\n",
        "\n",
        "        # Precompute M_inv once\n",
        "        M = tf.constant([\n",
        "            [0.51388889, 0.31944444, 0.04166667, 0., 0., 0., 0.],\n",
        "            [0.11111111, 0.55555556, 0.33333333, 0., 0., 0., 0.],\n",
        "            [0., 0.125, 0.70833333, 0.16666667, 0., 0., 0.],\n",
        "            [0., 0., 0.16666667, 0.66666667, 0.16666667, 0., 0.],\n",
        "            [0., 0., 0., 0.16666667, 0.70833333, 0.125, 0.],\n",
        "            [0., 0., 0., 0., 0.33333333, 0.55555556, 0.11111111],\n",
        "            [0., 0., 0., 0., 0.04166667, 0.31944444, 0.51388889]\n",
        "        ], dtype=tf.float32)\n",
        "        M_inv_value = tf.linalg.inv(M)\n",
        "\n",
        "        # Store inverse as a non-trainable weight for saving/loading with the model\n",
        "        self.M_inv = self.add_weight(\n",
        "            name=\"M_inv\",\n",
        "            shape=(7, 7),\n",
        "            dtype=tf.float32,\n",
        "            initializer=tf.keras.initializers.Constant(M_inv_value),\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "    # Define the piecewise polynomial evaluation function inside the layer\n",
        "    @tf.function\n",
        "    def evaluate_f_piecewise(self, x, a0, a1, a2, a3, a4, a5, a6, a7, a8):\n",
        "        \"\"\"\n",
        "        Evaluates the piecewise cubic polynomial f(x) defined by a0..a4.\n",
        "        Uses the specific formulas provided by the user.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor shape (B, H, W).\n",
        "            a0..a4: Coefficient tensors shape (B, H, W).\n",
        "\n",
        "        Returns:\n",
        "            f(x): Evaluated polynomial tensor shape (B, H, W).\n",
        "        \"\"\"\n",
        "        # Ensure inputs have correct dtype\n",
        "        x = tf.cast(x, dtype=tf.float32)\n",
        "        a0 = tf.cast(a0, dtype=tf.float32)\n",
        "        a1 = tf.cast(a1, dtype=tf.float32)\n",
        "        a2 = tf.cast(a2, dtype=tf.float32)\n",
        "        a3 = tf.cast(a3, dtype=tf.float32)\n",
        "        a4 = tf.cast(a4, dtype=tf.float32)\n",
        "        a5 = tf.cast(a5, dtype=tf.float32)\n",
        "        a6 = tf.cast(a6, dtype=tf.float32)\n",
        "        a7 = tf.cast(a7, dtype=tf.float32)\n",
        "        a8 = tf.cast(a8, dtype=tf.float32)\n",
        "\n",
        "        # Calculate coefficients for polynomial terms (shapes B, H, W)\n",
        "        P0 = -9*a0 + 19*a1 - 13*a2 + 3*a3\n",
        "        Q0 = -54*a0 + 138*a1 - 120*a2 + 36*a3\n",
        "        S0 = -108*a0 + 300*a1 - 336*a2 + 144*a3\n",
        "        T0 = -72*a0 + 208*a1 - 256*a2 + 192*a3\n",
        "\n",
        "        P1 = -8*a1 + 23*a2 - 27*a3 + 12*a4\n",
        "        Q1 = -24*a1 + 96*a2 - 144*a3 + 72*a4\n",
        "        S1 = -24*a1 + 96*a2 - 216*a3 + 144*a4\n",
        "        T1 = -8*a1 + 32*a2 - 48*a3 + 96*a4\n",
        "\n",
        "        P2 = -3*a2 + 11*a3 - 12*a4 + 4*a5\n",
        "        Q2 = 12*a3 - 24*a4 + 12*a5\n",
        "        S2 = -12*a3 + 12*a5\n",
        "        T2 =  4*a3 + 16*a4 + 4*a5\n",
        "\n",
        "        P3 = -4*a3 + 12*a4 - 11*a5 + 3*a6\n",
        "        Q3 = 12*a3 - 24*a4 + 12*a5\n",
        "        S3 = -12*a3 + 12*a5\n",
        "        T3 = 4*a3 + 16*a4 + 4*a5\n",
        "\n",
        "        P4 = -12*a4 + 27*a5 - 23*a6 + 8*a7\n",
        "        Q4 = 72*a4 - 144*a5 + 96*a6 - 24*a7\n",
        "        S4 = -144*a4 + 216*a5 - 96*a6 + 24*a7\n",
        "        T4 = 96*a4 - 48*a5 + 32*a6 - 8*a7\n",
        "\n",
        "        P5 = -3*a5 + 13*a6 - 19*a7 + 9*a8\n",
        "        Q5 = 36*a5 - 120*a6 + 138*a7 - 54*a8\n",
        "        S5 = -144*a5 + 336*a6 - 300*a7 + 108*a8\n",
        "        T5 = 192*a5 - 256*a6 + 208*a7 - 72*a8\n",
        "\n",
        "        # Common coefficients for x^2, x^1, x^0 terms\n",
        "\n",
        "        x2 = x * x\n",
        "        x3 = x2 * x\n",
        "\n",
        "        # Evaluate polynomial for interval [-4, -2)\n",
        "        f_0 = (P0 * x3 + Q0 * x2 + S0 * x + T0) / 72\n",
        "\n",
        "        # Evaluate polynomial for interval [-2, -1)\n",
        "        f_1 = (P1 * x3 + Q1 * x2 + S1 * x + T1) / 72\n",
        "\n",
        "        # Evaluate polynomial for interval [-1, 0)\n",
        "        f_2 = (P2 * x3 + Q2 * x2 + S2 * x + T2) / 24\n",
        "\n",
        "        # Evaluate polynomial for interval [0, 1)\n",
        "        f_3 = (P3 * x3 + Q3 * x2 + S3 * x + T3) / 24\n",
        "\n",
        "        # Evaluate polynomial for interval [1, 2)\n",
        "        f_4 = (P4 * x3 + Q4 * x2 + S4 * x + T4) / 72\n",
        "\n",
        "        # Evaluate polynomial for interval [2, 4]\n",
        "        f_5 = (P5 * x3 + Q5 * x2 + S5 * x + T5) / 72\n",
        "\n",
        "        # Choose based on x value: Use f_neg if x < 0, use f_pos if x >= 0\n",
        "        f_val = tf.where(x < -2.0, f_0,\n",
        "                tf.where(x < -1.0, f_1,\n",
        "                tf.where(x <  0.0, f_2,\n",
        "                tf.where(x <  1.0, f_3,\n",
        "                tf.where(x <  2.0, f_4, f_5)))))\n",
        "\n",
        "        return f_val\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, features):\n",
        "        \"\"\"\n",
        "        Processes features according to the complex root-finding logic.\n",
        "\n",
        "        Args:\n",
        "            features: Tensor of shape (B, H, W, C) where C=5.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (B, H, W) containing the input value (from d or R0-R3)\n",
        "            that maximizes the underlying function f_ij. # CHANGED: minimizes to maximizes\n",
        "        \"\"\"\n",
        "        # Ensure input is float32\n",
        "        features = tf.cast(features, dtype=tf.float32)\n",
        "\n",
        "        shape = tf.shape(features)\n",
        "        B, H, W = shape[0], shape[1], shape[2]\n",
        "\n",
        "        # Assert shape dynamically\n",
        "        tf.debugging.assert_equal(tf.shape(features)[3], self.C_dim,\n",
        "                                message=f\"Input tensor must have C={self.C_dim} channels.\")\n",
        "\n",
        "        # --- Steps 1-8: Calculate a0..a4, A0, A1, B, C, deltas, R0..R3 ---\n",
        "\n",
        "        # 1. Extract Channels\n",
        "        c0 = features[..., 0]\n",
        "        c1 = features[..., 1]\n",
        "        c2 = features[..., 2]\n",
        "        c3 = features[..., 3]\n",
        "        c4 = features[..., 4]\n",
        "        c5 = features[..., 5]\n",
        "        c6 = features[..., 6]\n",
        "        c7 = features[..., 7]\n",
        "        c8 = features[..., 8]\n",
        "\n",
        "        # 2. Set Boundary `a` values\n",
        "        a0 = c0\n",
        "        a8 = c8\n",
        "\n",
        "        # 3. Solve Linear System for a1, a2, a3\n",
        "        R_val = tf.stack([c1 - 0.125 * c0, c2, c3, c4, c5, c6, c7 - 0.125*c8], axis=-1)\n",
        "        a_vec = tf.linalg.matvec(self.M_inv, R_val) # Use stored M_inv\n",
        "        a1 = a_vec[..., 0]\n",
        "        a2 = a_vec[..., 1]\n",
        "        a3 = a_vec[..., 2]\n",
        "        a4 = a_vec[..., 3]\n",
        "        a5 = a_vec[..., 4]\n",
        "        a6 = a_vec[..., 5]\n",
        "        a7 = a_vec[..., 6]\n",
        "\n",
        "        # End Steps 1-3\n",
        "        a_coeffs = [a0, a1, a2, a3, a4, a5, a6, a7, a8]\n",
        "        R_values = tf.linspace(-4.0, 4.0, 81)  # Shape: (81,)\n",
        "\n",
        "        x_broadcastable = tf.reshape(R_values, (1, 1, 1, 81))\n",
        "        a_coeffs_broadcastable = [tf.expand_dims(a, axis=-1) for a in a_coeffs]\n",
        "        all_candidate_fs = self.evaluate_f_piecewise(x_broadcastable, *a_coeffs_broadcastable)\n",
        "\n",
        "        # Ensure output is float32\n",
        "        return tf.cast(all_candidate_fs, dtype=tf.float32)\n",
        "\n",
        "def disparityregression(input):\n",
        "    shape = K.shape(input)\n",
        "    disparity_values = np.linspace(-4, 4, 81)\n",
        "    x = K.constant(disparity_values, shape=[81])\n",
        "    x = K.expand_dims(K.expand_dims(K.expand_dims(x, 0), 0), 0)\n",
        "    x = tf.tile(x, [shape[0], shape[1], shape[2], 1])\n",
        "    out = K.sum(multiply([input, x]), -1)\n",
        "    return out\n",
        "\n",
        "\n",
        "def define_9BS_SubFocal(sz_input, sz_input2, view_n, learning_rate):\n",
        "    \"\"\" 81 inputs\"\"\"\n",
        "    input_list = []\n",
        "    for i in range(len(view_n) * len(view_n)):\n",
        "        input_list.append(Input(shape=(sz_input, sz_input2, 1)))\n",
        "    \"\"\" 81 features\"\"\"\n",
        "    feature_extraction_layer = feature_extraction(sz_input, sz_input2)\n",
        "\n",
        "    feature_list = []\n",
        "    for i in range(len(view_n) * len(view_n)):\n",
        "        feature_list.append(feature_extraction_layer(input_list[i]))\n",
        "    \"\"\" cost volume \"\"\"\n",
        "    cv = Lambda(_getCostVolume_)(feature_list)\n",
        "    \"\"\" channel attention \"\"\"\n",
        "    cv, attention = channel_attention(cv)\n",
        "    \"\"\" cost volume regression \"\"\"\n",
        "    cost = basic(cv)\n",
        "    cost = Lambda(lambda x: K.permute_dimensions(K.squeeze(x, -1),\n",
        "                                                 (0, 2, 3, 1)))(cost)\n",
        "    BSpline_layer = BSplineLayer(name='BSplineInterpolation')\n",
        "    cost_refined = BSpline_layer(cost)\n",
        "\n",
        "    pred = Activation('softmax')(cost_refined)\n",
        "\n",
        "    pred = Lambda(disparityregression)(pred)\n",
        "\n",
        "    model = Model(inputs=input_list, outputs=[pred])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    opt = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='mae')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_size = 32  # Input size should be greater than or equal to 23\n",
        "    label_size = 32  # Since label_size should be greater than or equal to 1\n",
        "    # number of views ( 0~8 for 9x9 )\n",
        "    AngualrViews = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "    T1 = time.time()\n",
        "    model = define_9BS_SubFocal(input_size, input_size, AngualrViews, 0.001)\n",
        "    T2 = time.time()\n",
        "    print('model load: %s s' % ((T2 - T1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVehGJ0uNLAj"
      },
      "source": [
        "# 2.3. pfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9o1q2vjNSFz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def read_pfm(fpath, expected_identifier=\"Pf\"):\n",
        "    # PFM format definition: http://netpbm.sourceforge.net/doc/pfm.html\n",
        "\n",
        "    def _get_next_line(f):\n",
        "        next_line = f.readline().decode('utf-8').rstrip()\n",
        "        # ignore comments\n",
        "        while next_line.startswith('#'):\n",
        "            next_line = f.readline().rstrip()\n",
        "        return next_line\n",
        "\n",
        "    with open(fpath, 'rb') as f:\n",
        "        #  header\n",
        "        identifier = _get_next_line(f)\n",
        "        if identifier != expected_identifier:\n",
        "            raise Exception('Unknown identifier. Expected: \"%s\", got: \"%s\".' % (expected_identifier, identifier))\n",
        "\n",
        "        try:\n",
        "            line_dimensions = _get_next_line(f)\n",
        "            dimensions = line_dimensions.split(' ')\n",
        "            width = int(dimensions[0].strip())\n",
        "            height = int(dimensions[1].strip())\n",
        "        except:\n",
        "            raise Exception('Could not parse dimensions: \"%s\". '\n",
        "                            'Expected \"width height\", e.g. \"128 128\".' % line_dimensions)\n",
        "\n",
        "        try:\n",
        "            line_scale = _get_next_line(f)\n",
        "            scale = float(line_scale)\n",
        "            assert scale != 0\n",
        "            if scale < 0:\n",
        "                endianness = \"<\"\n",
        "            else:\n",
        "                endianness = \">\"\n",
        "        except:\n",
        "            raise Exception('Could not parse max value / endianess information: \"%s\". '\n",
        "                            'Should be a non-zero number.' % line_scale)\n",
        "\n",
        "        try:\n",
        "            data = np.fromfile(f, \"%sf\" % endianness)\n",
        "            data = np.reshape(data, (height, width))\n",
        "            data = np.flipud(data)\n",
        "            with np.errstate(invalid=\"ignore\"):\n",
        "                data *= abs(scale)\n",
        "        except:\n",
        "            raise Exception('Invalid binary values. Could not create %dx%d array from input.' % (height, width))\n",
        "\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wipDOaCWNSig"
      },
      "source": [
        "# 2.4. savedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsXfea99Nmw4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def display_current_output(train_output,\n",
        "                           traindata_label,\n",
        "                           iter00,\n",
        "                           directory_save,\n",
        "                           train_val='train'):\n",
        "    '''\n",
        "        display current results from CasLF\n",
        "        and save results in /current_output\n",
        "    '''\n",
        "    sz = len(traindata_label)\n",
        "    train_output = np.squeeze(train_output)\n",
        "    if (len(traindata_label.shape) > 3\n",
        "            and traindata_label.shape[-1] == 9):  # traindata\n",
        "        pad1_half = int(\n",
        "            0.5 * (np.size(traindata_label, 1) - np.size(train_output, 1)))\n",
        "        train_label120 = traindata_label[:, 4:-4, 4:-4, 4, 4]\n",
        "    else:  # valdata\n",
        "        pad1_half = int(\n",
        "            0.5 * (np.size(traindata_label, 1) - np.size(train_output, 1)))\n",
        "        train_label120 = traindata_label[:, 4:-4, 4:-4]\n",
        "\n",
        "    train_output120 = train_output[:, 4 - pad1_half:120 + 4 - pad1_half,\n",
        "                                   4 - pad1_half:120 + 4 - pad1_half]\n",
        "\n",
        "    train_diff = np.abs(train_output120 - train_label120)\n",
        "    train_bp = (train_diff >= 0.07)\n",
        "\n",
        "    train_output120_all = np.zeros((2 * 120, sz * 120), np.uint8)\n",
        "    train_output120_all[0:120, :] = np.uint8(\n",
        "        25 *\n",
        "        np.reshape(np.transpose(train_label120, (1, 0, 2)), (120, sz * 120)) +\n",
        "        100)\n",
        "    train_output120_all[120:2 * 120, :] = np.uint8(\n",
        "        25 *\n",
        "        np.reshape(np.transpose(train_output120, (1, 0, 2)), (120, sz * 120)) +\n",
        "        100)\n",
        "\n",
        "    imageio.imsave(\n",
        "        directory_save + '/' + train_val + '_iter%05d.jpg' % (iter00),\n",
        "        np.squeeze(train_output120_all))\n",
        "\n",
        "    return train_diff, train_bp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXuASVFjNnM1"
      },
      "source": [
        "# 2.5. util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrjeq99WN8FF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_LFdata(dir_LFimages):\n",
        "    target_shape = 128\n",
        "    # (number of scenes, width_images, lenght_images, 9, 9, RGB).\n",
        "    traindata_all = np.zeros((len(dir_LFimages), target_shape, target_shape, 9, 9, 3), np.uint8)\n",
        "    traindata_label = np.zeros((len(dir_LFimages), target_shape, target_shape), np.float32)\n",
        "\n",
        "    image_id = 0\n",
        "    for dir_LFimage in dir_LFimages:\n",
        "        print(dir_LFimage)\n",
        "        for i in range(81):\n",
        "            try:\n",
        "                tmp = np.float32(\n",
        "                    imageio.imread('full_data/' + dir_LFimage +\n",
        "                                   '/input_Cam0%.2d.png' %\n",
        "                                   i))  # load LF images(9x9)\n",
        "                tmp_resized = cv2.resize(tmp, (target_shape, target_shape), interpolation=cv2.INTER_AREA)\n",
        "            except:\n",
        "                print('full_data/' + dir_LFimage +\n",
        "                      '/input_Cam0%.2d.png..does not exist' % i)\n",
        "            traindata_all[image_id, :, :, i // 9, i - 9 * (i // 9), :] = tmp_resized\n",
        "            del tmp, tmp_resized\n",
        "        try:\n",
        "            tmp = np.float32(\n",
        "                read_pfm('full_data/' + dir_LFimage +\n",
        "                         '/gt_disp_lowres.pfm'))  # load LF disparity map\n",
        "            tmp_resized = cv2.resize(tmp, (target_shape, target_shape), interpolation=cv2.INTER_AREA)\n",
        "        except:\n",
        "            print('full_data/' + dir_LFimage +\n",
        "                  '/gt_disp_lowres.pfm..does not exist' % i)\n",
        "        traindata_label[image_id, :, :] = tmp_resized\n",
        "        del tmp, tmp_resized\n",
        "        image_id = image_id + 1\n",
        "    return traindata_all, traindata_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKydRvESYVWo"
      },
      "source": [
        "# 3. train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlVw6K7cdpcR"
      },
      "source": [
        "## 3.1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQZ18q8_4g90",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    '''\n",
        "    Load Train data from LF .png files\n",
        "    '''\n",
        "    print('Load training data...')\n",
        "    dir_LFimages = [\n",
        "        'additional/antinous', 'additional/boardgames', 'additional/dishes',\n",
        "        'additional/greek', 'additional/kitchen', 'additional/medieval2',\n",
        "        'additional/museum', 'additional/pens', 'additional/pillows',\n",
        "        'additional/platonic', 'additional/rosemary', 'additional/table',\n",
        "        'additional/tomb', 'additional/tower', 'additional/town',\n",
        "        'additional/vinyl'\n",
        "    ]\n",
        "    # For fold 2 use\n",
        "    # print('Load training data...')\n",
        "    # dir_LFimages = [\n",
        "    #     'additional/antinous', 'additional/boardgames', 'additional/dishes',\n",
        "    #     'additional/greek', 'additional/kitchen', 'additional/medieval2',\n",
        "    #     'additional/museum', 'stratified/backgammon', 'stratified/dots',\n",
        "    #     'stratified/pyramids', 'stratified/stripes', 'training/boxes',\n",
        "    #     'training/cotton', 'training/dino', 'training/sideboard'\n",
        "    # ]\n",
        "\n",
        "    # For fold 3 use\n",
        "    # dir_LFimages = [\n",
        "    #     'stratified/backgammon', 'stratified/dots', 'stratified/pyramids',\n",
        "    #     'stratified/stripes', 'training/boxes', 'training/cotton',\n",
        "    #     'training/dino', 'training/sideboard', 'additional/pillows',\n",
        "    #     'additional/platonic', 'additional/rosemary', 'additional/table',\n",
        "    #     'additional/tomb', 'additional/tower', 'additional/town',\n",
        "    #     'additional/vinyl'\n",
        "    # ]\n",
        "\n",
        "    traindata_all, traindata_label = load_LFdata(dir_LFimages)\n",
        "\n",
        "    print('Load training data... Complete')\n",
        "\n",
        "    '''\n",
        "    Load Test data from LF .png files\n",
        "    '''\n",
        "    print('Load test data...')\n",
        "    dir_LFimages = [\n",
        "        'stratified/backgammon', 'stratified/dots', 'stratified/pyramids',\n",
        "        'stratified/stripes', 'training/boxes', 'training/cotton',\n",
        "        'training/dino', 'training/sideboard'\n",
        "    ]\n",
        "\n",
        "    # For fold 2 use\n",
        "    # dir_LFimages = [\n",
        "    #     'stratified/backgammon', 'stratified/dots', 'stratified/pyramids',\n",
        "    #     'stratified/stripes', 'training/boxes', 'training/cotton',\n",
        "    #     'training/dino', 'training/sideboard'\n",
        "    # ]\n",
        "    # For fold 3 use\n",
        "    # dir_LFimages = [\n",
        "    #     'additional/antinous', 'additional/boardgames', 'additional/dishes',\n",
        "    #     'additional/greek', 'additional/kitchen', 'additional/medieval2',\n",
        "    #     'additional/museum', 'additional/pens'\n",
        "    # ]\n",
        "\n",
        "    valdata_all, valdata_label = load_LFdata(dir_LFimages)\n",
        "\n",
        "    print('Load test data... Complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbYrWPAl84HW",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(f'train:{traindata_all.shape}  label:{traindata_label.shape}')\n",
        "print(f'val:{valdata_all.shape}  label:{valdata_label.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd-IiQfAdvUA"
      },
      "source": [
        "## 3.2. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaHjKpAaoxjg",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def setup_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "\n",
        "def save_disparity_jet(disparity, filename):\n",
        "    max_disp = np.nanmax(disparity[disparity != np.inf])\n",
        "    min_disp = np.nanmin(disparity[disparity != np.inf])\n",
        "    disparity = (disparity - min_disp) / (max_disp - min_disp)\n",
        "    disparity = (disparity * 255.0).astype(np.uint8)\n",
        "    disparity = cv2.applyColorMap(disparity, cv2.COLORMAP_JET)\n",
        "    cv2.imwrite(filename, disparity)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    '''\n",
        "    We use fit_generator to train LF,\n",
        "    so here we defined a generator function.\n",
        "    '''\n",
        "\n",
        "    class threadsafe_iter:\n",
        "        \"\"\"\n",
        "        Takes an iterator/generator and makes it thread-safe by\n",
        "        serializing call to the `next` method of given iterator/generator.\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, it):\n",
        "            self.it = it\n",
        "            self.lock = threading.Lock()\n",
        "\n",
        "        def __iter__(self):\n",
        "            return self\n",
        "\n",
        "        def __next__(self):\n",
        "            with self.lock:\n",
        "                return next(self.it)\n",
        "\n",
        "    def threadsafe_generator(f):\n",
        "        \"\"\"\n",
        "        A decorator that takes a generator function and makes it thread-safe.\n",
        "        \"\"\"\n",
        "\n",
        "        def g(*a, **kw):\n",
        "            return threadsafe_iter(f(*a, **kw))\n",
        "\n",
        "        return g\n",
        "\n",
        "    @threadsafe_generator\n",
        "    def myGenerator(traindata_all, traindata_label, input_size, label_size,\n",
        "                    batch_size, AngualrViews, boolmask_img4, boolmask_img6,\n",
        "                    boolmask_img15):\n",
        "        while 1:\n",
        "            (traindata_batch,\n",
        "             traindata_label_batchNxN) = generate_traindata_for_train(\n",
        "                 traindata_all, traindata_label, input_size, label_size,\n",
        "                 batch_size, AngualrViews, boolmask_img4, boolmask_img6,\n",
        "                 boolmask_img15)\n",
        "\n",
        "            (traindata_batch,\n",
        "             traindata_label_batchNxN) = data_augmentation_for_train(\n",
        "                 traindata_batch, traindata_label_batchNxN, batch_size)\n",
        "\n",
        "            traindata_batch_list = []\n",
        "            for i in range(traindata_batch.shape[3]):\n",
        "                for j in range(traindata_batch.shape[4]):\n",
        "                    traindata_batch_list.append(\n",
        "                        np.expand_dims(traindata_batch[:, :, :, i, j],\n",
        "                                       axis=-1))\n",
        "\n",
        "            yield (traindata_batch_list, traindata_label_batchNxN)\n",
        "\n",
        "    # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
        "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "\n",
        "    seed = 42\n",
        "    setup_seed(seed)\n",
        "    print(\"random seed: \", seed)\n",
        "\n",
        "    '''\n",
        "    Define Patch-wise training parameters\n",
        "    '''\n",
        "    input_size = 32  # Input size should be greater than or equal to 23 32\n",
        "    label_size = 32  # Since label_size should be greater than or equal to 1\n",
        "    # number of views ( 0~8 for 9x9 )\n",
        "    AngualrViews = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "    batch_size = 8\n",
        "    workers_num = 8  # number of threads\n",
        "\n",
        "    display_status_ratio = 2000  # 10000\n",
        "\n",
        "    iter00 = 20\n",
        "\n",
        "    load_weight_is = False\n",
        "\n",
        "    model_learning_rate = 0.001\n",
        "    networkname = '9BS_SubFocal'\n",
        "\n",
        "    traindata, _ = generate_traindata128(traindata_all, traindata_label,\n",
        "                                         AngualrViews)\n",
        "\n",
        "    valdata, valdata_label = generate_traindata128(valdata_all, valdata_label,\n",
        "                                                   AngualrViews)\n",
        "\n",
        "    '''load invalid regions from training data (ex. reflective region)'''\n",
        "    boolmask_img4 = imageio.imread(\n",
        "        'full_data/additional_invalid_area/kitchen/input_Cam040_invalid_ver2.png'\n",
        "    )\n",
        "    boolmask_img6 = imageio.imread(\n",
        "        'full_data/additional_invalid_area/museum/input_Cam040_invalid_ver2.png'\n",
        "    )\n",
        "    boolmask_img15 = imageio.imread(\n",
        "        'full_data/additional_invalid_area/vinyl/input_Cam040_invalid_ver2.png'\n",
        "    )\n",
        "\n",
        "    boolmask_img4 = 1.0 * boolmask_img4[:, :, 3] > 0\n",
        "    boolmask_img6 = 1.0 * boolmask_img6[:, :, 3] > 0\n",
        "    boolmask_img15 = 1.0 * boolmask_img15[:, :, 3] > 0\n",
        "\n",
        "    '''\n",
        "    Model for patch-wise training\n",
        "    '''\n",
        "    model = define_9BS_SubFocal(input_size, input_size, AngualrViews,\n",
        "                            model_learning_rate)\n",
        "    model.load_weights('9BSfold2_LF_checkpoint/9BSfold2_SubFocal_sub_0.5_ckp/iter0020_valmse4.963_bp25.53.hdf5')\n",
        "    '''\n",
        "    Model for predicting full-size LF images\n",
        "    '''\n",
        "    image_w = 128\n",
        "    image_h = 128\n",
        "    model_128 = define_9BS_SubFocal(image_w, image_h, AngualrViews,\n",
        "                                model_learning_rate)\n",
        "    \"\"\"\n",
        "    load latest_checkpoint\n",
        "    \"\"\"\n",
        "    if load_weight_is:\n",
        "        model.load_weights(\n",
        "            'LF_checkpoint/SubFocal_sub_0.5_ckp/iter0049_valmse0.845_bp2.04.hdf5'\n",
        "        )\n",
        "\n",
        "    '''\n",
        "    Define directory for saving checkpoint file & disparity output image\n",
        "    '''\n",
        "    LF_checkpoints_path = '9BSfold2_LF_checkpoint/'\n",
        "    LF_output_path = '9BSfold2_LF_output/'\n",
        "\n",
        "    directory_ckp = LF_checkpoints_path + \"%s_ckp\" % (networkname)\n",
        "    if not os.path.exists(directory_ckp):\n",
        "        os.makedirs(directory_ckp)\n",
        "\n",
        "    if not os.path.exists(LF_output_path):\n",
        "        os.makedirs(LF_output_path)\n",
        "    directory_t = LF_output_path + '%s' % (networkname)\n",
        "    if not os.path.exists(directory_t):\n",
        "        os.makedirs(directory_t)\n",
        "\n",
        "    txt_name = LF_checkpoints_path + 'lf_%s.txt' % (networkname)\n",
        "    \"\"\"\n",
        "    Write date & time\n",
        "    \"\"\"\n",
        "    f1 = open(txt_name, 'a')\n",
        "    now = datetime.datetime.now()\n",
        "    f1.write('\\n' + str(now) + '\\n\\n')\n",
        "    f1.write('Learning rate: {}\\n'.format(model_learning_rate))\n",
        "    f1.write('Batch size: {}\\n\\n'.format(batch_size))\n",
        "    f1.close()\n",
        "\n",
        "\n",
        "    my_generator = myGenerator(traindata_all, traindata_label, input_size,\n",
        "                               label_size, batch_size, AngualrViews,\n",
        "                               boolmask_img4, boolmask_img6, boolmask_img15)\n",
        "    best_bad_pixel = 25.51  #100.0\n",
        "    val_output = model_128.predict(valdata, batch_size=1)\n",
        "    print(\"test!!!\")\n",
        "\n",
        "    # Get a batch from the generator\n",
        "    traindata_batch_list, traindata_label_batchNxN = next(my_generator)\n",
        "\n",
        "    for iter02 in range(20, 40):\n",
        "        ''' Patch-wise training... start'''\n",
        "        print(f'EPOCH {iter02+1} STARTS')\n",
        "        t0 = time.time()\n",
        "        history = model.fit_generator(my_generator,\n",
        "                            steps_per_epoch=int(display_status_ratio),\n",
        "                            epochs=iter00 + 1,\n",
        "                            class_weight=None,\n",
        "                            max_queue_size=10,\n",
        "                            initial_epoch=iter00,\n",
        "                            verbose=1,\n",
        "                            workers=workers_num)\n",
        "\n",
        "        iter00 = iter00 + 1\n",
        "        '''Get the training loss from the history'''\n",
        "        loss = history.history['loss'][-1]\n",
        "        ''' Test after N*(display_status_ratio) iteration.'''\n",
        "        weight_tmp1 = model.get_weights()\n",
        "        model_128.set_weights(weight_tmp1)\n",
        "        \"\"\" Validation \"\"\"\n",
        "        ''' Test after N*(display_status_ratio) iteration.'''\n",
        "\n",
        "        val_output = model_128.predict(valdata, batch_size=1)\n",
        "        ''' Save prediction image(disparity map) in 'current_output/' folder '''\n",
        "        val_error, val_bp = display_current_output(val_output, valdata_label,\n",
        "                                                   iter00, directory_t, 'val')\n",
        "\n",
        "        validation_mean_squared_error_x100 = 100 * \\\n",
        "            np.average(np.square(val_error))\n",
        "        validation_bad_pixel_ratio = 100 * np.average(val_bp)\n",
        "\n",
        "        save_path_file_new = (directory_ckp +\n",
        "                              '/iter%04d_valmse%.3f_bp%.2f.hdf5' %\n",
        "                              (iter00, validation_mean_squared_error_x100,\n",
        "                               validation_bad_pixel_ratio))\n",
        "        \"\"\"\n",
        "        Save bad pixel & mean squared error\n",
        "        \"\"\"\n",
        "        print(save_path_file_new)\n",
        "        f1 = open(txt_name, 'a')\n",
        "        f1.write('.' + save_path_file_new + f'  loss={loss:.4f}\\n')\n",
        "        f1.close()\n",
        "        t1 = time.time()\n",
        "        ''' save model weights if it get better results than previous one...'''\n",
        "        if (validation_bad_pixel_ratio < best_bad_pixel):\n",
        "            best_bad_pixel = validation_bad_pixel_ratio\n",
        "            model.save(save_path_file_new)\n",
        "            print(\"saved!!!\")\n",
        "        else:\n",
        "            model.save(save_path_file_new)\n",
        "\n",
        "        print(f'EPOCH {iter02+1} ENDS')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cu124.m129",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu124:m129"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}